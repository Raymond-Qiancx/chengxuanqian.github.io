---
layout: about
title: about
permalink: /
subtitle: <a href='#'>Affiliations</a>. Address. Contacts. Moto. Etc.

profile:
  align: right
  image: prof_pic.jpg
  image_circular: false # crops the image to make it circular
  more_info: >


news: true # includes a list of news items
selected_papers: true # includes a list of papers marked as "selected={true}"
social: true # includes social icons at the bottom of the page
---

I'm Chengxuan Qian, a second-year undergraduate student in Jiangsu University and a incoming transfer student in Arcadia University(Philadelphia, USA)([2+2 Program](https://www.arcadia.edu/news/arcadia-and-jiangsu-university-celebrate-10-years-of-collaboration/)). I am broadly interested at Computer Vision and Multimodal Learning. In particular, I'm interested in Dynamic Multimodal Fusion, Efficient Meachine Learning Systems, Visual Question Answering and Medical Image Segmentation & Classification.

When I was a freshman. I started my research supervised by [Prof. Zhe Liu](https://www.researchgate.net/profile/Zhe-Liu-28) in Jiangsu University and [Prof. Victor S. Sheng](https://scholar.google.com/citations?user=0epc43IAAAAJ&hl=zh-CN) in Texas Tech University remotely. My first program is to help construct the world's first public multi-task medical image benchmark dataset for liver and tumor segmentation, multi-label lesion classification and lesion detection based on arterial phase enhanced computed tomography (CT). This work has submitted to ***Medical Image Analysis*** (A Top Journal in Medical Imaging, IF:10.9). After that, we started to focus on Noisy Label, a serious but inevitable challenge for medical image segmentation. We proposed a novel Nosiy Label Adaptative Refinement Framework and submitted it to the journal ***Engineering Applications of Artificial Intelligence*** (SCI Q1, IF: 8.0). Currently, I conduct the research about Efficient Machine Learning Framework for General Multimodal Classification based on Curriculum Learning. This work will soon submit to ***AAAI 2025*** and I will be the first-author.

I'm now seaching for Undergraduate Research Internship in the field of Multimodal Learning, especially for Dynamic Multimodal fusion, Inter-modal Interactions(VQA), Video Understanding, 3D Multi-view and sensors, human behavior modeling and Medical Vision. My email address is raymond.qiancx at gmail dot com.
